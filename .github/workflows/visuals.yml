name: Generate Sentence Transcriptions

on:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/visuals.json'
      - 'Trans/transcription.json'
  workflow_dispatch:

jobs:
  generate-transcriptions:
    runs-on: ubuntu-latest

    # Add permissions for GITHUB_TOKEN
    permissions:
      contents: write
      actions: read

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        ref: main  # ‚úÖ Explicitly checkout the main branch

    - name: Verify branch and status
      run: |
        git branch
        git status

    - name: Pull latest changes
      run: |
        git config --local user.name "intellectra9"
        git config --local user.email "intellectra9@outlook.com"
        git pull origin main --rebase || git pull origin main

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Generate sentence transcriptions
      run: |
        python3 << 'EOF'
        import json
        import os
        import re

        def load_json_file(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as file:
                    return json.load(file)
            except FileNotFoundError:
                print(f"Error: File {file_path} not found")
                return None
            except json.JSONDecodeError:
                print(f"Error: Invalid JSON in {file_path}")
                return None

        def clean_word(word):
            return re.sub(r'[^\w\s]', '', word.lower().strip())

        def find_sentence_in_sequence(sentence_words, word_segments, start_index=0):
            if not sentence_words or start_index >= len(word_segments):
                return -1, -1, start_index

            current_index = start_index

            while current_index < len(word_segments):
                word_cleaned = clean_word(word_segments[current_index]['word'])

                if word_cleaned == sentence_words[0]:
                    sentence_start_index = current_index
                    temp_index = current_index
                    matched_words = 0
                    sentence_end_index = -1

                    for sentence_word in sentence_words:
                        found = False
                        search_range = min(temp_index + 5, len(word_segments))

                        for search_idx in range(temp_index, search_range):
                            if search_idx >= len(word_segments):
                                break
                            search_word_cleaned = clean_word(word_segments[search_idx]['word'])

                            if search_word_cleaned == sentence_word:
                                matched_words += 1
                                sentence_end_index = search_idx
                                temp_index = search_idx + 1
                                found = True
                                break

                        if not found:
                            break

                    match_ratio = matched_words / len(sentence_words)
                    if match_ratio >= 0.7:
                        return sentence_start_index, sentence_end_index, sentence_end_index + 1

                current_index += 1

            return -1, -1, current_index

        def create_sentence_transcription(visuals_data, transcription_data):
            sentence_transcriptions = []
            word_segments = transcription_data.get('word_segments', [])

            if not word_segments:
                print("Error: No word_segments found in transcription data")
                return []

            current_word_index = 0

            for item in visuals_data:
                sentence = item.get('sentence', '')
                sentence_number = item.get('number', 0)

                if not sentence:
                    print(f"Warning: Empty sentence for item {sentence_number}")
                    continue

                sentence_words = [clean_word(word) for word in sentence.split() if clean_word(word)]

                if not sentence_words:
                    print(f"Warning: No valid words in sentence {sentence_number}")
                    continue

                start_idx, end_idx, next_start = find_sentence_in_sequence(
                    sentence_words, word_segments, current_word_index
                )

                if start_idx >= 0 and end_idx >= 0:
                    start_time = word_segments[start_idx]['start']
                    end_time = word_segments[end_idx]['end']

                    transcription_item = {
                        "id": f"i{sentence_number}",
                        "number": sentence_number,
                        "sentence": sentence,
                        "start": start_time,
                        "end": end_time,
                        "duration": round(end_time - start_time, 3)
                    }
                    sentence_transcriptions.append(transcription_item)
                    current_word_index = next_start

                    print(f"‚úì Sentence {sentence_number}: {start_time}s - {end_time}s")
                else:
                    print(f"‚úó Could not find sentence {sentence_number} in transcription")
                    transcription_item = {
                        "id": f"i{sentence_number}",
                        "number": sentence_number,
                        "sentence": sentence,
                        "start": None,
                        "end": None,
                        "duration": None
                    }
                    sentence_transcriptions.append(transcription_item)

            return sentence_transcriptions

        def main():
            visuals_file = "Visuals/visuals.json"
            transcription_file = "Trans/transcription.json"
            output_file = "Edits/edit.json"

            os.makedirs("Edits", exist_ok=True)

            print("Loading visuals data...")
            visuals_data = load_json_file(visuals_file)
            if not visuals_data:
                print("Failed to load visuals data")
                exit(1)

            print("Loading transcription data...")
            transcription_data = load_json_file(transcription_file)
            if not transcription_data:
                print("Failed to load transcription data")
                exit(1)

            print(f"Processing {len(visuals_data)} sentences sequentially...")

            sentence_transcriptions = create_sentence_transcription(visuals_data, transcription_data)

            if sentence_transcriptions:
                output_data = {
                    "sentence_transcriptions": sentence_transcriptions,
                    "total_sentences": len(sentence_transcriptions),
                    "successful_matches": len([s for s in sentence_transcriptions if s['start'] is not None]),
                    "metadata": {
                        "generated_by": "sequential_sentence_transcription_generator",
                        "source_files": {
                            "visuals": visuals_file,
                            "transcription": transcription_file
                        }
                    }
                }

                try:
                    with open(output_file, 'w', encoding='utf-8') as file:
                        json.dump(output_data, file, indent=2, ensure_ascii=False)

                    successful = output_data['successful_matches']
                    total = output_data['total_sentences']
                    print(f"\nüéâ Successfully created {output_file}")
                    print(f"üìä Results: {successful}/{total} sentences matched with timestamps")

                except Exception as e:
                    print(f"Error saving output file: {e}")
                    exit(1)
            else:
                print("No sentence transcriptions were created")
                exit(1)

        if __name__ == "__main__":
            main()
        EOF

    - name: Commit and push results
      env:
        GITHUB_TOKEN: ${{ secrets.GH_PAT }}
      run: |
        git config --local user.email "intellectra9@outlook.com"
        git config --local user.name "intellectra9"

        git remote set-url origin https://intellectra9:${{ secrets.GH_PAT }}@github.com/intellectra9/intellect.git

        if [[ -f "Edits/edit.json" ]]; then
          git add Edits/edit.json

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            total=$(jq '.total_sentences' Edits/edit.json)
            matched=$(jq '.successful_matches' Edits/edit.json)

            git commit -m "ü§ñ Auto-generate sentence transcriptions

- Generated sentence-level timestamps from word-level transcription
- Processed ${total} sentences
- Successfully matched ${matched} sentences with timestamps"

            git pull origin main --rebase || git pull origin main

            git push origin HEAD:${{ github.ref_name }}
            echo "‚úÖ Sentence transcriptions committed and pushed!"
          fi
        else
          echo "‚ùå Edits/edit.json was not created"
          exit 1
        fi

    - name: Upload artifact
      uses: actions/upload-artifact@v3
      with:
        name: sentence-transcriptions
        path: Edits/edit.json
