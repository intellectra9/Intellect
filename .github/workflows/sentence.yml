name: Generate Sentence Level Transcription

on:
  workflow_run:
    workflows: ["transcript.yml"]  # Replace with the actual name of your transcript workflow
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    
    # Only run if the triggering workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Generate sentence-level transcription
        run: |
          python3 << 'EOF'
          import json
          import os
          import re
          from datetime import datetime

          def clean_word(word):
              return re.sub(r'[^\w\s]', '', word.lower())

          def find_sentence_span(sentence_words, word_segments, start_idx, max_gap=20.0):
              current_idx = start_idx
              first_match = None
              last_match = None

              for word in sentence_words:
                  target = clean_word(word)
                  found = False
                  for idx in range(current_idx, len(word_segments)):
                      seg_word = clean_word(word_segments[idx]['word'])
                      if seg_word == target:
                          if first_match is None:
                              first_match = idx
                          last_match = idx
                          current_idx = idx + 1
                          found = True
                          break
                  if not found:
                      continue  # allow partial match

              if first_match is not None and last_match is not None:
                  start_time = word_segments[first_match]['start']
                  end_time = word_segments[last_match]['end']
                  if (end_time - start_time) > max_gap:
                      print(f"‚ö†Ô∏è Large gap detected ({end_time - start_time}s) for sentence. Using fallback end time.")
                      end_time = min(start_time + 2.0, word_segments[-1]['end'])
                      last_match = first_match

                  next_idx = max(last_match + 1, start_idx + 1)
                  return start_time, end_time, next_idx
              else:
                  print("‚ö†Ô∏è No good match found. Skipping ahead safely.")
                  next_idx = min(start_idx + 5, len(word_segments))
                  return None, None, next_idx

          def main():
              try:
                  with open('Visuals/visuals.json', 'r', encoding='utf-8') as f:
                      visuals = json.load(f)
                  print(f"Loaded {len(visuals)} sentences.")
              except Exception as e:
                  print(f"Error loading visuals.json: {e}")
                  return

              try:
                  with open('Trans/transcription.json', 'r', encoding='utf-8') as f:
                      transcription = json.load(f)
                  word_segments = transcription.get('word_segments', [])
                  print(f"Loaded {len(word_segments)} word segments.")
              except Exception as e:
                  print(f"Error loading transcription.json: {e}")
                  return

              results = []
              start_idx = 0

              for item in visuals:
                  sentence = item['sentence']
                  num = item['number']
                  words = sentence.split()
                  print(f"\n‚û°Ô∏è Processing sentence {num}: '{sentence[:50]}...'")

                  start, end, next_idx = find_sentence_span(words, word_segments, start_idx)

                  if start is not None and end is not None:
                      result = {
                          "id": f"i{num}",
                          "number": num,
                          "sentence": sentence,
                          "start": round(start, 3),
                          "end": round(end, 3),
                          "duration": round(end - start, 3)
                      }
                      results.append(result)
                      print(f"‚úÖ Found: {start}s to {end}s (next_idx={next_idx})")
                  else:
                      print(f"‚ùå Could not match sentence {num}")

                  start_idx = next_idx

              os.makedirs('Edits', exist_ok=True)
              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total_sentences": len(results),
                      "source_files": {
                          "visuals": "Visuals/visuals.json",
                          "transcription": "Trans/transcription.json"
                      }
                  },
                  "sentence_transcriptions": results
              }

              with open('Edits/edit.json', 'w', encoding='utf-8') as f:
                  json.dump(output, f, indent=2, ensure_ascii=False)

              print(f"\nüéâ Saved Edits/edit.json with {len(results)} sentences.")

          if __name__ == '__main__':
              main()
          EOF

      - name: Configure Git
        run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"

      - name: Commit and push transcription file
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git stash --include-untracked
          git pull origin main --rebase || echo "No rebase needed"
          git stash pop || true

          git add Edits/edit.json
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "üîÑ Generated sentence transcription: ${timestamp}" || echo "No changes to commit"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main
