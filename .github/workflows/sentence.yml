name: Generate Sentence Level Transcription

on:
  workflow_dispatch:  # Manual trigger
  push:
    branches: [ main ]
    paths: 
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Process transcription files
        run: |
          python3 << 'EOF'
          import json
          import os
          import re
          from datetime import datetime

          def clean_word(word):
              """Clean word for matching"""
              return re.sub(r'[^\w\s]', '', word.lower().strip())

          def find_sentence_span(sentence_words, word_segments, start_idx):
              """
              Sequentially find first and last word positions for sentence.
              Always moves forward so sentences don’t overlap or stall.
              """
              current_idx = start_idx
              first_match = None
              last_match = None

              for sentence_word in sentence_words:
                  target = clean_word(sentence_word)
                  found = False

                  for idx in range(current_idx, len(word_segments)):
                      seg_word = clean_word(word_segments[idx]['word'])
                      if seg_word == target:
                          if first_match is None:
                              first_match = idx
                          last_match = idx
                          current_idx = idx + 1  # Move after match
                          found = True
                          break

                  if not found:
                      continue  # Allow partial matches

              if first_match is not None and last_match is not None:
                  next_idx = max(last_match + 1, start_idx + 1)
                  return first_match, last_match, next_idx
              else:
                  # No match: skip ahead to avoid stalling
                  print("⚠️ No match, skipping ahead by 5")
                  next_idx = min(start_idx + 5, len(word_segments))
                  return -1, -1, next_idx

          def main():
              # Load visuals
              with open('Visuals/visuals.json', 'r', encoding='utf-8') as f:
                  visuals = json.load(f)
              print(f"Loaded {len(visuals)} sentences")

              # Load word-level transcription
              with open('Trans/transcription.json', 'r', encoding='utf-8') as f:
                  transcription = json.load(f)
              word_segments = transcription.get('word_segments', [])
              print(f"Loaded {len(word_segments)} word segments")

              results = []
              current_start_idx = 0

              for item in visuals:
                  sentence = item['sentence']
                  number = item['number']
                  words = [w for w in sentence.split() if w]

                  if not words:
                      print(f"⚠️ Sentence {number} is empty")
                      continue

                  s_idx, e_idx, next_idx = find_sentence_span(words, word_segments, current_start_idx)

                  if s_idx >= 0 and e_idx >= 0:
                      start_time = word_segments[s_idx]['start']
                      end_time = word_segments[e_idx]['end']
                      results.append({
                          "id": f"i{number}",
                          "number": number,
                          "sentence": sentence,
                          "start": start_time,
                          "end": end_time,
                          "duration": round(end_time - start_time, 3)
                      })
                      print(f"✓ Sentence {number}: {start_time}-{end_time}s")
                  else:
                      print(f"✗ Could not match sentence {number}")
                  
                  current_start_idx = next_idx

              os.makedirs('Edits', exist_ok=True)
              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total_sentences": len(results),
                      "source_files": {
                          "visuals": "Visuals/visuals.json",
                          "transcription": "Trans/transcription.json"
                      }
                  },
                  "sentence_transcriptions": results
              }
              with open('Edits/edit.json', 'w', encoding='utf-8') as f:
                  json.dump(output, f, indent=2, ensure_ascii=False)

              print(f"✅ Done. Saved Edits/edit.json with {len(results)} sentences.")

          if __name__ == '__main__':
              main()
          EOF
          
      - name: Set up Git identity
        run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"
          
      - name: Commit and push transcription file
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git stash --include-untracked
          git pull origin main --rebase || echo "Warning: rebase skipped"
          git stash pop || true

          git add Edits/edit.json
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "Generated sentence transcription: ${timestamp}" || echo "No changes to commit"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main
