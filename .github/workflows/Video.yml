name: Generate Fast Smooth Video

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v3  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.10'  

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          pip install requests pillow

      - name: Create fast smooth video script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          from PIL import Image
          import shutil

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"

          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          print("ğŸš€ Fast smooth video generation...")

          # === Load and validate ===
          if not all(os.path.exists(f) for f in [AUDIO_FILE, EDIT_JSON, IMAGES_DIR]):
              print("âŒ Missing required files")
              sys.exit(1)

          with open(EDIT_JSON, "r") as f:
              edit_data = json.load(f)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])
          if not sentence_transcriptions:
              print("âŒ No sentence transcriptions found")
              sys.exit(1)

          # === Process segments quickly ===
          valid_segments = []
          for i, segment in enumerate(sentence_transcriptions):
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              
              if end_time <= start_time:
                  continue

              image_path = os.path.join(IMAGES_DIR, f"{segment_id}.png")
              if not os.path.exists(image_path):
                  print(f"âš ï¸ Missing: {segment_id}.png")
                  continue

              # Quick image processing
              try:
                  with Image.open(image_path) as img:
                      if img.mode != 'RGB':
                          img = img.convert('RGB')
                      img.thumbnail((1920, 1080), Image.Resampling.LANCZOS)
                      
                      new_img = Image.new('RGB', (1920, 1080), (0, 0, 0))
                      x = (1920 - img.width) // 2
                      y = (1080 - img.height) // 2
                      new_img.paste(img, (x, y))
                      
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path)

                  valid_segments.append({
                      "id": segment_id,
                      "image_path": processed_path,
                      "start": start_time,
                      "end": end_time
                  })
              except Exception as e:
                  print(f"âŒ Error processing {segment_id}: {e}")

          if not valid_segments:
              print("âŒ No valid segments")
              sys.exit(1)

          valid_segments.sort(key=lambda x: x["start"])
          print(f"âœ… {len(valid_segments)} segments ready")

          # === Get audio duration fast ===
          try:
              result = subprocess.run([
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ], capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
          except:
              total_duration = max(seg["end"] for seg in valid_segments)

          # === Fix timing gaps (key optimization) ===
          # This is the ONLY change needed to fix black screens!
          for i, segment in enumerate(valid_segments):
              if i == 0 and segment["start"] > 0:
                  segment["start"] = 0  # Start first image at 0
              
              if i < len(valid_segments) - 1:
                  next_start = valid_segments[i + 1]["start"]
                  # Extend current image until next one starts
                  segment["end"] = next_start
              else:
                  # Last image extends to end
                  segment["end"] = total_duration

          # === Generate video in single FFmpeg call ===
          print("ğŸ¬ Generating video (single pass)...")
          
          output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          input_args = ["-i", AUDIO_FILE]
          
          # Add image inputs
          for segment in valid_segments:
              input_args.extend(["-loop", "1", "-i", segment["image_path"]])

          # Build fast filter
          filter_parts = []
          
          # Scale images efficiently
          for i in range(len(valid_segments)):
              filter_parts.append(
                  f"[{i+1}:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                  f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2,fps=30[v{i}];"
              )

          # Create base and overlay (simplified)
          filter_parts.append(f"color=black:size=1920x1080:duration={total_duration}:rate=30[base];")
          
          current = "[base]"
          for i, segment in enumerate(valid_segments):
              next_stream = f"[out{i}]" if i < len(valid_segments) - 1 else "[video]"
              
              # Simple, fast enable condition
              filter_parts.append(
                  f"{current}[v{i}]overlay=enable='gte(t,{segment['start']})*lt(t,{segment['end']})'{next_stream};"
              )
              current = next_stream

          filter_complex = "".join(filter_parts)

          # Fast FFmpeg command
          cmd = [
              "ffmpeg", "-y"
          ] + input_args + [
              "-filter_complex", filter_complex,
              "-map", "[video]",
              "-map", "0:a",
              "-c:v", "libx264",
              "-preset", "fast",  # Fast preset
              "-crf", "23",
              "-c:a", "aac",
              "-b:a", "192k",
              "-t", str(total_duration),
              output_path
          ]

          print("âš¡ Running fast generation...")
          try:
              subprocess.run(cmd, capture_output=True, text=True, check=True)
              print("âœ… Fast generation completed!")
              
              if os.path.exists(output_path):
                  size_mb = os.path.getsize(output_path) / (1024*1024)
                  print(f"ğŸ“Š Output: {size_mb:.2f} MB")
              
          except subprocess.CalledProcessError as e:
              print(f"âŒ Generation failed: {e}")
              print(f"stderr: {e.stderr}")
              sys.exit(1)

          # Quick cleanup
          shutil.rmtree(TEMP_DIR, ignore_errors=True)
          print("ğŸ‰ Fast smooth video ready!")
          EOF

      - name: Run fast video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "ğŸš€ Fast smooth video: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ secrets.GH_PAT }}  
          git push origin HEAD:main
