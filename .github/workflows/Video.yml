name: Generate Video (Optimized)

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v4  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.11'  

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies  
        run: |  
          pip install requests pillow

      - name: Create optimized video generation script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          from PIL import Image
          import tempfile
          import shutil
          from concurrent.futures import ThreadPoolExecutor
          import time

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"

          # Create necessary directories
          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          start_time = time.time()
          print("ğŸ¬ Starting optimized seamless video generation...")

          # === Validate required files ===
          required_files = [AUDIO_FILE, EDIT_JSON]
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f"âŒ Required file not found: {file_path}")
                  sys.exit(1)

          if not os.path.exists(IMAGES_DIR):
              print(f"âŒ Images directory not found: {IMAGES_DIR}")
              sys.exit(1)

          print("âœ… All required files found")

          # === Load and validate edit.json ===
          try:
              with open(EDIT_JSON, "r") as f:
                  edit_data = json.load(f)
          except json.JSONDecodeError as e:
              print(f"âŒ Invalid JSON format in {EDIT_JSON}: {e}")
              sys.exit(1)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])
          if not sentence_transcriptions:
              print("âŒ No sentence transcriptions found")
              sys.exit(1)

          print(f"ğŸ“ Found {len(sentence_transcriptions)} segments")

          # === Get audio duration first ===
          print("ğŸ” Getting audio duration...")
          try:
              duration_cmd = [
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ]
              result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
              print(f"ğŸ“Š Audio duration: {total_duration:.2f} seconds")
          except Exception as e:
              print(f"âŒ Error getting audio duration: {e}")
              sys.exit(1)

          # === Process images in parallel ===
          def process_image(segment_data):
              i, segment = segment_data
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              duration = end_time - start_time

              if duration <= 0:
                  return None, f"Invalid duration for segment {segment_id}"

              image_filename = f"{segment_id}.png"
              image_path = os.path.join(IMAGES_DIR, image_filename)

              if not os.path.exists(image_path):
                  return None, f"Image not found: {image_filename}"

              try:
                  with Image.open(image_path) as img:
                      # Convert to RGB
                      if img.mode != 'RGB':
                          img = img.convert('RGB')
                      
                      # Resize maintaining aspect ratio
                      img.thumbnail((1920, 1080), Image.Resampling.LANCZOS)
                      
                      # Create centered image on black background
                      new_img = Image.new('RGB', (1920, 1080), (0, 0, 0))
                      x = (1920 - img.width) // 2
                      y = (1080 - img.height) // 2
                      new_img.paste(img, (x, y))
                      
                      # Save processed image
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path, "PNG", optimize=True)

                  return {
                      "id": segment_id,
                      "image_path": processed_path,
                      "start": start_time,
                      "end": end_time,
                      "duration": duration
                  }, None

              except Exception as e:
                  return None, f"Error processing {image_filename}: {e}"

          # Process images in parallel
          print("ğŸ–¼ï¸ Processing images in parallel...")
          with ThreadPoolExecutor(max_workers=4) as executor:
              results = list(executor.map(process_image, enumerate(sentence_transcriptions)))

          # Collect valid segments and errors
          valid_segments = []
          errors = []

          for result, error in results:
              if result:
                  valid_segments.append(result)
              if error:
                  errors.append(error)

          if errors:
              print(f"âš ï¸ Issues found: {len(errors)}")
              for error in errors[:5]:  # Show first 5 errors
                  print(f"  - {error}")

          if not valid_segments:
              print("âŒ No valid segments found")
              sys.exit(1)

          # Sort by start time
          valid_segments.sort(key=lambda x: x["start"])
          print(f"âœ… Processed {len(valid_segments)} segments")

          # === Fill gaps between segments ===
          print("ğŸ”§ Filling gaps between segments...")
          filled_segments = []
          
          for i, segment in enumerate(valid_segments):
              filled_segments.append(segment)
              
              # Check if there's a gap before the next segment
              if i < len(valid_segments) - 1:
                  next_segment = valid_segments[i + 1]
                  gap_start = segment["end"]
                  gap_end = next_segment["start"]
                  
                  if gap_end > gap_start + 0.1:  # Gap larger than 0.1 seconds
                      # Extend current segment to fill the gap
                      segment["end"] = gap_end
                      segment["duration"] = gap_end - segment["start"]
                      print(f"ğŸ”— Extended segment {segment['id']} to fill gap: {gap_start:.2f}s -> {gap_end:.2f}s")

          # Extend last segment to end of audio if needed
          if valid_segments:
              last_segment = valid_segments[-1]
              if last_segment["end"] < total_duration:
                  last_segment["end"] = total_duration
                  last_segment["duration"] = total_duration - last_segment["start"]
                  print(f"ğŸ”š Extended last segment to audio end: {last_segment['end']:.2f}s")

          # === Create seamless video ===
          print("ğŸ¥ Creating seamless video...")
          
          output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          
          # Build optimized FFmpeg command
          input_args = ["-i", AUDIO_FILE]
          
          # Add all images as inputs
          for segment in valid_segments:
              input_args.extend(["-loop", "1", "-i", segment["image_path"]])
          
          # Create filter complex for seamless transitions
          filter_parts = []
          
          # Scale all images to exact dimensions
          for i, segment in enumerate(valid_segments):
              input_idx = i + 1
              filter_parts.append(f"[{input_idx}:v]scale=1920:1080,fps=30,format=yuv420p[v{i}];")
          
          # Create timeline with no gaps
          if len(valid_segments) == 1:
              # Single segment case
              segment = valid_segments[0]
              filter_parts.append(f"[v0]trim=0:{segment['duration']},setpts=PTS-STARTPTS+{segment['start']}/TB[final];")
          else:
              # Multiple segments with seamless transitions
              concat_inputs = []
              for i, segment in enumerate(valid_segments):
                  # Create segment with exact duration
                  filter_parts.append(f"[v{i}]trim=0:{segment['duration']},setpts=PTS-STARTPTS[s{i}];")
                  concat_inputs.append(f"[s{i}]")
              
              # Concatenate all segments
              filter_parts.append(f"{''.join(concat_inputs)}concat=n={len(valid_segments)}:v=1:a=0[final];")
          
          filter_complex = "".join(filter_parts)
          
          # Build final FFmpeg command
          ffmpeg_cmd = [
              "ffmpeg", "-y",
              "-hide_banner", "-loglevel", "warning"
          ] + input_args + [
              "-filter_complex", filter_complex,
              "-map", "[final]",
              "-map", "0:a",
              "-c:v", "libx264",
              "-preset", "fast",
              "-crf", "23",
              "-c:a", "aac",
              "-b:a", "192k",
              "-pix_fmt", "yuv420p",
              "-movflags", "+faststart",
              "-t", str(total_duration),
              output_path
          ]
          
          print("ğŸ”§ Executing FFmpeg...")
          try:
              result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True)
              
              if os.path.exists(output_path):
                  file_size = os.path.getsize(output_path) / (1024*1024)
                  elapsed = time.time() - start_time
                  
                  print("âœ… Video generation completed successfully!")
                  print(f"ğŸ“ Output: {output_path}")
                  print(f"ğŸ“Š Size: {file_size:.2f} MB")
                  print(f"â±ï¸ Time: {elapsed:.2f} seconds")
              else:
                  print("âŒ Output file not created")
                  sys.exit(1)
                  
          except subprocess.CalledProcessError as e:
              print(f"âŒ FFmpeg failed: {e}")
              print(f"stderr: {e.stderr}")
              
              # Fallback method with simpler approach
              print("ğŸ”„ Trying fallback method...")
              
              # Create simple concatenation
              segments_file = os.path.join(TEMP_DIR, "segments.txt")
              with open(segments_file, "w") as f:
                  for segment in valid_segments:
                      f.write(f"file '{segment['image_path']}'\n")
                      f.write(f"duration {segment['duration']}\n")
                  # Add last image again to avoid truncation
                  if valid_segments:
                      f.write(f"file '{valid_segments[-1]['image_path']}'\n")
              
              fallback_cmd = [
                  "ffmpeg", "-y",
                  "-f", "concat",
                  "-safe", "0",
                  "-i", segments_file,
                  "-i", AUDIO_FILE,
                  "-c:v", "libx264",
                  "-preset", "fast",
                  "-crf", "23",
                  "-c:a", "aac",
                  "-b:a", "192k",
                  "-pix_fmt", "yuv420p",
                  "-shortest",
                  output_path
              ]
              
              try:
                  result = subprocess.run(fallback_cmd, capture_output=True, text=True, check=True)
                  print("âœ… Fallback method succeeded!")
              except subprocess.CalledProcessError as e2:
                  print(f"âŒ Fallback method failed: {e2}")
                  sys.exit(1)

          # === Cleanup ===
          try:
              shutil.rmtree(TEMP_DIR, ignore_errors=True)
          except:
              pass
          
          total_time = time.time() - start_time
          print(f"ğŸ‰ Complete! Total time: {total_time:.2f} seconds")
          print("ğŸ”Š Seamless audio-video sync achieved!")
          print("ğŸ“º No black screen transitions!")
          EOF

      - name: Run optimized video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "ğŸ¬ Generated optimized seamless video: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git  
          git push origin HEAD:main
