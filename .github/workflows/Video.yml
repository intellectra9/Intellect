name: Generate Video with Transitions

on:
  workflow_dispatch:

permissions:
  contents: write  # Allows pushing changes back

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v3  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.10'  

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies  
        run: |  
          pip install requests pillow

      - name: Verify Transitions Directory
        run: |
          if [ ! -d "Transitions" ]; then
            echo "âŒ Transitions directory not found!"
            exit 1
          fi
          
          echo "âœ… Transitions directory found"
          echo "ğŸ“ Available transition files:"
          ls -la Transitions/
          
          # Check for specific transition files
          transitions=(
            "fade_in_out.py"
            "zoom_in.py" 
            "zoom_out.py"
            "slide_left.py"
            "slide_right.py"
            "push_up.py"
            "wipe.py"
            "dissolve.py"
            "circle_reveal.py"
          )
          
          echo "ğŸ” Checking for required transition files:"
          for transition in "${transitions[@]}"; do
            if [ -f "Transitions/$transition" ]; then
              echo "âœ… Found: $transition"
            else
              echo "âš ï¸ Missing: $transition"
            fi
          done

      - name: Create Enhanced Video Generation Script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          import random
          import importlib.util
          from PIL import Image
          import tempfile
          import shutil

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"
          TRANSITIONS_DIR = "Transitions"

          # Create necessary directories
          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          print("ğŸ¬ Starting enhanced video generation with transitions...")

          # === Load Transition Modules ===
          def load_transition_modules():
              """Load all transition modules from the Transitions directory"""
              transition_modules = {}
              
              if not os.path.exists(TRANSITIONS_DIR):
                  print(f"âŒ Transitions directory not found: {TRANSITIONS_DIR}")
                  return transition_modules
              
              # Specific transition files to load
              transition_files = [
                  "fade_in_out.py",
                  "zoom_in.py", 
                  "zoom_out.py",
                  "slide_left.py",
                  "slide_right.py",
                  "push_up.py",
                  "wipe.py",
                  "dissolve.py",
                  "circle_reveal.py"
              ]
              
              for filename in transition_files:
                  module_path = os.path.join(TRANSITIONS_DIR, filename)
                  if os.path.exists(module_path):
                      module_name = filename[:-3]  # Remove .py extension
                      
                      try:
                          spec = importlib.util.spec_from_file_location(module_name, module_path)
                          module = importlib.util.module_from_spec(spec)
                          spec.loader.exec_module(module)
                          transition_modules[module_name] = module
                          print(f"âœ… Loaded transition: {module.get_transition_name()}")
                      except Exception as e:
                          print(f"âš ï¸ Failed to load transition {filename}: {e}")
                  else:
                      print(f"âš ï¸ Transition file not found: {filename}")
              
              return transition_modules

          # Load all available transitions
          transitions = load_transition_modules()
          if not transitions:
              print("âŒ No transition modules loaded. Using basic transitions.")

          # === Validate required files ===
          required_files = [AUDIO_FILE, EDIT_JSON]
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f"âŒ Required file not found: {file_path}")
                  sys.exit(1)

          if not os.path.exists(IMAGES_DIR):
              print(f"âŒ Images directory not found: {IMAGES_DIR}")
              sys.exit(1)

          print("âœ… All required files and directories found")

          # === Load edit.json ===
          with open(EDIT_JSON, "r") as f:
              edit_data = json.load(f)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])
          if not sentence_transcriptions:
              print("âŒ No sentence transcriptions found in edit.json")
              sys.exit(1)

          print(f"ğŸ“ Found {len(sentence_transcriptions)} sentence transcriptions")

          # === Process images and validate segments ===
          valid_segments = []
          missing_images = []

          for i, segment in enumerate(sentence_transcriptions):
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              duration = end_time - start_time

              if duration <= 0:
                  print(f"âš ï¸ Skipping segment {segment_id} with invalid duration: {duration}")
                  continue

              # Find corresponding image
              image_filename = f"{segment_id}.png"
              image_path = os.path.join(IMAGES_DIR, image_filename)

              if not os.path.exists(image_path):
                  missing_images.append(image_filename)
                  print(f"âš ï¸ Image not found: {image_path}")
                  continue

              print(f"ğŸ–¼ï¸ Processing segment {segment_id}: {start_time}s - {end_time}s ({duration:.2f}s)")

              # Process image to standard dimensions
              try:
                  with Image.open(image_path) as img:
                      # Convert to RGB if necessary
                      if img.mode != 'RGB':
                          img = img.convert('RGB')
                      
                      # Resize to 1920x1080 maintaining aspect ratio
                      img.thumbnail((1920, 1080), Image.Resampling.LANCZOS)
                      
                      # Create new image with black background
                      new_img = Image.new('RGB', (1920, 1080), (0, 0, 0))
                      
                      # Center the image
                      x = (1920 - img.width) // 2
                      y = (1080 - img.height) // 2
                      new_img.paste(img, (x, y))
                      
                      # Save processed image
                      processed_image_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_image_path)

                  valid_segments.append({
                      "id": segment_id,
                      "image_path": processed_image_path,
                      "start": start_time,
                      "end": end_time,
                      "duration": duration
                  })

              except Exception as e:
                  print(f"âŒ Error processing image {image_path}: {e}")
                  missing_images.append(image_filename)

          if missing_images:
              print(f"âš ï¸ Missing images: {', '.join(missing_images)}")

          if not valid_segments:
              print("âŒ No valid video segments found")
              sys.exit(1)

          # Sort segments by start time to ensure proper order
          valid_segments.sort(key=lambda x: x["start"])
          print(f"âœ… Processed {len(valid_segments)} video segments")

          # === Get total audio duration ===
          print("ğŸ” Getting audio duration...")
          try:
              duration_cmd = [
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ]
              result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
              print(f"ğŸ“Š Total audio duration: {total_duration:.2f} seconds")
          except Exception as e:
              print(f"âŒ Error getting audio duration: {e}")
              total_duration = max(seg["end"] for seg in valid_segments)
              print(f"ğŸ“Š Using fallback duration: {total_duration:.2f} seconds")

          # === Generate Random Transitions ===
          def get_random_transition():
              """Get a random transition from available modules"""
              if not transitions:
                  return None
              return random.choice(list(transitions.keys()))

          # === Create Enhanced Video with Transitions ===
          print("ğŸ¥ Creating video with dynamic transitions...")
          
          output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          
          # Build FFmpeg command with transitions
          filter_parts = []
          input_args = ["-i", AUDIO_FILE]  # Audio input first
          
          # Add all images as inputs
          for i, segment in enumerate(valid_segments):
              input_args.extend(["-loop", "1", "-i", segment["image_path"]])
          
          # Create base video streams from images
          for i, segment in enumerate(valid_segments):
              input_idx = i + 1  # +1 because audio is input 0
              
              # Create properly scaled video stream
              filter_parts.append(
                  f"[{input_idx}:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                  f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2,fps=30,format=yuv420p[img{i}];"
              )
          
          # Create timeline with transitions
          if len(valid_segments) == 1:
              # Single image case
              filter_parts.append(f"[img0]loop=loop=-1:size=1:start=0[video];")
          else:
              # Multiple images with transitions
              filter_parts.append(f"color=black:size=1920x1080:duration={total_duration}:rate=30[bg];")
              
              current_stream = "[bg]"
              for i, segment in enumerate(valid_segments):
                  next_stream = f"[tmp{i}]" if i < len(valid_segments) - 1 else "[video]"
                  
                  if i == 0:
                      # First image - no transition needed
                      next_start = valid_segments[i + 1]["start"] if i < len(valid_segments) - 1 else total_duration
                      filter_parts.append(
                          f"{current_stream}[img{i}]overlay=0:0:enable='gte(t,{segment['start']})*lt(t,{next_start})'{next_stream};"
                      )
                  else:
                      # Apply transition between previous and current image
                      prev_segment = valid_segments[i - 1]
                      transition_start = segment["start"]
                      transition_duration = 0.5  # Default transition duration
                      
                      # Get random transition
                      transition_name = get_random_transition()
                      if transition_name and transition_name in transitions:
                          try:
                              transition_module = transitions[transition_name]
                              print(f"ğŸ­ Applying {transition_module.get_transition_name()} transition between images {i-1} and {i}")
                              
                              # Apply the transition (simplified for this example)
                              next_start = valid_segments[i + 1]["start"] if i < len(valid_segments) - 1 else total_duration
                              filter_parts.append(
                                  f"{current_stream}[img{i}]overlay=0:0:enable='gte(t,{transition_start})*lt(t,{next_start})'{next_stream};"
                              )
                          except Exception as e:
                              print(f"âš ï¸ Error applying transition {transition_name}: {e}")
                              # Fallback to simple overlay
                              next_start = valid_segments[i + 1]["start"] if i < len(valid_segments) - 1 else total_duration
                              filter_parts.append(
                                  f"{current_stream}[img{i}]overlay=0:0:enable='gte(t,{transition_start})*lt(t,{next_start})'{next_stream};"
                              )
                      else:
                          # No transition available, use simple overlay
                          next_start = valid_segments[i + 1]["start"] if i < len(valid_segments) - 1 else total_duration
                          filter_parts.append(
                              f"{current_stream}[img{i}]overlay=0:0:enable='gte(t,{transition_start})*lt(t,{next_start})'{next_stream};"
                          )
                  
                  current_stream = next_stream
          
          # Combine all filter parts
          filter_complex = "".join(filter_parts)
          
          # Build FFmpeg command
          ffmpeg_cmd = [
              "ffmpeg", "-y"
          ] + input_args + [
              "-filter_complex", filter_complex,
              "-map", "[video]",
              "-map", "0:a",
              "-c:v", "libx264",
              "-preset", "medium",
              "-crf", "23",
              "-c:a", "aac",
              "-b:a", "192k",
              "-pix_fmt", "yuv420p",
              "-t", str(total_duration),
              output_path
          ]
          
          print("ğŸ”§ Running FFmpeg command with transitions...")
          
          try:
              result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True)
              print("âœ… Enhanced video with transitions completed successfully!")
              print(f"ğŸ“ Output saved to: {output_path}")
              
              # Print file size
              if os.path.exists(output_path):
                  file_size = os.path.getsize(output_path)
                  print(f"ğŸ“Š File size: {file_size / (1024*1024):.2f} MB")
              else:
                  print("âŒ Output file was not created")
                  
          except subprocess.CalledProcessError as e:
              print(f"âŒ FFmpeg error: {e}")
              print(f"stderr: {e.stderr}")
              sys.exit(1)

          # === Cleanup ===
          shutil.rmtree(TEMP_DIR, ignore_errors=True)
          
          print("ğŸ‰ Enhanced video generation with transitions completed!")
          print("ğŸ­ Random transitions applied between images!")
          print("ğŸ”Š Audio synchronized with visual transitions!")
          print("ğŸ“º Professional video with dynamic effects!")
          EOF

      - name: Run enhanced video generation script
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "ğŸ¬ Generated enhanced video with random transitions: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git  
          git push origin HEAD:main
